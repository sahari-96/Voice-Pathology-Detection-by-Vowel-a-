{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sQ9PFqgmYkO6"
      },
      "outputs": [],
      "source": [
        "#import libraries (some of them may not be used)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "import keras\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\n",
        "from keras import backend as K\n",
        "from keras.activations import sigmoid\n",
        "from keras import layers\n",
        "from keras import initializers\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout, BatchNormalization,Embedding, LSTM, Reshape, Bidirectional,Conv1D, MaxPooling1D, AveragePooling1D, Conv2D, MaxPooling2D, Conv3D, MaxPooling3D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import wave\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "from keras import regularizers\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential, Model, model_from_json, load_model\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
        "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
        "from keras import losses, models, optimizers\n",
        "from keras.activations import relu, softmax\n",
        "from tensorflow.keras.utils import to_categorical, custom_object_scope\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm, tqdm_pandas\n",
        "import scipy\n",
        "import librosa\n",
        "import librosa.display\n",
        "import json\n",
        "from matplotlib.pyplot import specgram\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import sys\n",
        "import warnings\n",
        "# ignore warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here we connect to google drive to access our datasets\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaJphviQbq-t",
        "outputId": "fad3ed7f-ede2-490c-8786-27bc919b90fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction (LPC and MFCC)"
      ],
      "metadata": {
        "id": "v4lUr6QN13if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1=[]\n",
        "a2=[]\n",
        "a3=[]"
      ],
      "metadata": {
        "id": "1Ly_PP2QbyuW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b1=[]\n",
        "b2=[]\n",
        "b3=[]"
      ],
      "metadata": {
        "id": "vsyknFNBcriu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting LPC features from the train data and put them in a list whit their filenames\n",
        "\n",
        "for file in glob.glob(\"/content/drive/MyDrive/train_02/*.wav\"):\n",
        "    y, sr = librosa.load(file, sr=None)\n",
        "    n_fft = 2048  # Frame size\n",
        "    hop_length = 512  # Hop length for 75% overlap\n",
        "    frames = librosa.util.frame(y, frame_length=n_fft, hop_length=hop_length).T\n",
        "    lpc_features = []\n",
        "    for frame in frames:\n",
        "        lpc_coeffs = librosa.lpc(frame, order=20)\n",
        "        lpc_features.append(lpc_coeffs)\n",
        "    lpc_features = np.array(lpc_features)\n",
        "    filename = Path(file).stem\n",
        "    identifier = filename.split(\"_\")[0]\n",
        "    a1.append([identifier, lpc_features])\n"
      ],
      "metadata": {
        "id": "Gv50HUsQb5Bg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting LPC features from the validation data and put them in a list whit their filenames\n",
        "\n",
        "for file in glob.glob(\"/content/drive/MyDrive/valid_02/*.wav\"):\n",
        "    y, sr = librosa.load(file, sr=None)\n",
        "    n_fft = 2048  # Frame size\n",
        "    hop_length = 512  # Hop length for 75% overlap\n",
        "    frames = librosa.util.frame(y, frame_length=n_fft, hop_length=hop_length).T\n",
        "    lpc_features = []\n",
        "    for frame in frames:\n",
        "        lpc_coeffs = librosa.lpc(frame, order=20)\n",
        "        lpc_features.append(lpc_coeffs)\n",
        "    lpc_features = np.array(lpc_features)\n",
        "    filename = Path(file).stem\n",
        "    identifier = filename.split(\"_\")[0]\n",
        "    a2.append([identifier, lpc_features])"
      ],
      "metadata": {
        "id": "VGj8orEacZp2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting LPC features from the test data and put them in a list whit their filenames\n",
        "\n",
        "for file in glob.glob(\"/content/drive/MyDrive/test_02/*.wav\"):\n",
        "    y, sr = librosa.load(file, sr=None)\n",
        "    n_fft = 2048  # Frame size\n",
        "    hop_length = 512  # Hop length for 75% overlap\n",
        "    frames = librosa.util.frame(y, frame_length=n_fft, hop_length=hop_length).T\n",
        "    lpc_features = []\n",
        "    for frame in frames:\n",
        "        lpc_coeffs = librosa.lpc(frame, order=20)\n",
        "        lpc_features.append(lpc_coeffs)\n",
        "    lpc_features = np.array(lpc_features)\n",
        "    filename = Path(file).stem\n",
        "    identifier = filename.split(\"_\")[0]\n",
        "    a3.append([identifier, lpc_features])"
      ],
      "metadata": {
        "id": "jbBz2eWPckvt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting MFCC features from the train data and put them in a list whit their filenames\n",
        "\n",
        "for file in glob.glob(\"/content/drive/MyDrive/train_02/*.wav\"):\n",
        "\n",
        "        y1, sr1 = librosa.load(file, sr = None, mono=True)\n",
        "        mfccs1= librosa.feature.mfcc(y=y1, sr=sr1, n_mfcc=13)\n",
        "        filename1 = Path(file).stem\n",
        "        x1 = filename1.split(\"_\")\n",
        "        b1.append([x1[0],mfccs1])"
      ],
      "metadata": {
        "id": "_87STuSucxOJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting MFCC features from the validation data and put them in a list whit their filenames\n",
        "\n",
        "for file in glob.glob(\"/content/drive/MyDrive/valid_02/*.wav\"):\n",
        "\n",
        "        y2, sr2 = librosa.load(file, sr = None, mono=True)\n",
        "        mfccs2= librosa.feature.mfcc(y=y2, sr=sr2,n_mfcc=13)\n",
        "        filename2 = Path(file).stem\n",
        "        x2 = filename2.split(\"_\")\n",
        "        b2.append([x2[0],mfccs2])"
      ],
      "metadata": {
        "id": "nAWmqUfLdnyz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting MFCC features from the test data and put them in a list whit their filenames\n",
        "\n",
        "for file in glob.glob(\"/content/drive/MyDrive/test_02/*.wav\"):\n",
        "\n",
        "        y3, sr3 = librosa.load(file, sr = None, mono=True)\n",
        "        mfccs3= librosa.feature.mfcc(y=y3, sr=sr3, n_mfcc=13)\n",
        "        filename3 = Path(file).stem\n",
        "        x3 = filename3.split(\"_\")\n",
        "        b3.append([x3[0],mfccs3])"
      ],
      "metadata": {
        "id": "u_Y7jReEd9KT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(a1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdvqvHdjeNOH",
        "outputId": "643ef73b-db5b-415b-f792-6a1e640fcb10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "460"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the number of frames for each sample is differen, here we get the (Average + STD) of the frame numbers for each LPC-based and MFCC-based Dataset(train + valid + test)."
      ],
      "metadata": {
        "id": "MhX8Nij42AfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = []\n",
        "s2 = []\n",
        "s3 = []"
      ],
      "metadata": {
        "id": "sUE3ecIOftp5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = []\n",
        "f2 = []\n",
        "f3 = []"
      ],
      "metadata": {
        "id": "Wsze7saZea-Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (460):\n",
        "  f1.append(len((b1[i][1]).T))\n",
        "for i in range (105):\n",
        "  f2.append(len((b2[i][1]).T))\n",
        "for i in range (142):\n",
        "  f3.append(len((b3[i][1]).T))"
      ],
      "metadata": {
        "id": "MUmGOK8CehMh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (460):\n",
        "  s1.append(len((a1[i][1])))\n",
        "for i in range (105):\n",
        "  s2.append(len((a2[i][1])))\n",
        "for i in range (142):\n",
        "  s3.append(len((a3[i][1])))"
      ],
      "metadata": {
        "id": "MJE3uIs0f4NI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s4 = s1 + s2 + s3"
      ],
      "metadata": {
        "id": "WBWVZSq2f4hv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f4 = f1 + f2 + f3"
      ],
      "metadata": {
        "id": "52gElmy_elyQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F4 = np.array(f4)"
      ],
      "metadata": {
        "id": "_8h3Rc9jexQZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S4 = np.array(s4)"
      ],
      "metadata": {
        "id": "nhntr0l8gJJC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ave = np.mean(F4)\n",
        "s = np.std(F4)\n",
        "print(min(F4))\n",
        "print(ave)\n",
        "print(s)\n",
        "print(ave+s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSafCxIRe1NL",
        "outputId": "3c20606c-594c-41a7-90a8-0fb905d669b3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "358\n",
            "1370.025459688826\n",
            "675.1442064427769\n",
            "2045.1696661316028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ave = np.mean(S4)\n",
        "s = np.std(S4)\n",
        "print(min(S4))\n",
        "print(ave)\n",
        "print(s)\n",
        "print(ave+s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PqE31rkgR5r",
        "outputId": "2cca358c-01a6-4a24-f51d-218f19fdc85d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354\n",
            "1366.025459688826\n",
            "675.1442064427769\n",
            "2041.1696661316028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making X_train, X_test, X_valid and Y_train, Y_test, Y_valid for LPC and MFCC based datasets"
      ],
      "metadata": {
        "id": "plHtbGBj3Sks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c1=[]\n",
        "c2=[]\n",
        "c3=[]"
      ],
      "metadata": {
        "id": "MtDGkRPYffm8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d1=[]\n",
        "d2=[]\n",
        "d3=[]"
      ],
      "metadata": {
        "id": "_wpdAjmvfoyv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(460):\n",
        "        c1.append([a1[i][0], ((a1[i][1]))[0:2040]])\n",
        "for i in range(105):\n",
        "        c2.append([a2[i][0], ((a2[i][1]))[0:2040]])\n",
        "for i in range(142):\n",
        "        c3.append([a3[i][0], ((a3[i][1]))[0:2040]])"
      ],
      "metadata": {
        "id": "6gKC3svHi8yl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(460):\n",
        "        d1.append([b1[i][0], ((b1[i][1]).T)[0:2045]])\n",
        "for i in range(105):\n",
        "        d2.append([b2[i][0], ((b2[i][1]).T)[0:2045]])\n",
        "for i in range(142):\n",
        "        d3.append([b3[i][0], ((b3[i][1]).T)[0:2045]])"
      ],
      "metadata": {
        "id": "Lbu7Rb4KjP2C"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_LPC =[]\n",
        "data_valid_LPC =[]\n",
        "data_test_LPC =[]"
      ],
      "metadata": {
        "id": "jo05zI8DjrkN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_MFCC =[]\n",
        "data_valid_MFCC =[]\n",
        "data_test_MFCC =[]"
      ],
      "metadata": {
        "id": "aEHvhBY3jvyB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we get our labels for each sample from this file\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/AVFAD_01_00_00.csv', encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "zw15ViRfj2oU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(460):\n",
        "    for j in range(709):\n",
        "        if c1[i][0] == df.iloc[j,0]:\n",
        "            data_train_LPC.append([c1[i][0], c1[i][1], df.iloc[j,15]])\n",
        "\n",
        "for i in range(105):\n",
        "    for j in range(709):\n",
        "        if c2[i][0] == df.iloc[j,0]:\n",
        "            data_valid_LPC.append([c2[i][0], c2[i][1], df.iloc[j,15]])\n",
        "\n",
        "for i in range(142):\n",
        "    for j in range(709):\n",
        "        if c3[i][0] == df.iloc[j,0]:\n",
        "            data_test_LPC.append([c3[i][0], c3[i][1], df.iloc[j,15]])"
      ],
      "metadata": {
        "id": "wJtPJVD-j9S5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(460):\n",
        "    for j in range(709):\n",
        "        if d1[i][0] == df.iloc[j,0]:\n",
        "            data_train_MFCC.append([d1[i][0], d1[i][1], df.iloc[j,15]])\n",
        "\n",
        "for i in range(105):\n",
        "    for j in range(709):\n",
        "        if d2[i][0] == df.iloc[j,0]:\n",
        "            data_valid_MFCC.append([d2[i][0], d2[i][1], df.iloc[j,15]])\n",
        "\n",
        "for i in range(142):\n",
        "    for j in range(709):\n",
        "        if d3[i][0] == df.iloc[j,0]:\n",
        "            data_test_MFCC.append([d3[i][0], d3[i][1], df.iloc[j,15]])"
      ],
      "metadata": {
        "id": "s0SOoiwEkGRu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_LPC.sort(key = lambda x: x[0])\n",
        "data_valid_LPC.sort(key = lambda x: x[0])\n",
        "data_test_LPC.sort(key = lambda x: x[0])"
      ],
      "metadata": {
        "id": "PUJ07QmflWRi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_MFCC.sort(key = lambda x: x[0])\n",
        "data_valid_MFCC.sort(key = lambda x: x[0])\n",
        "data_test_MFCC.sort(key = lambda x: x[0])"
      ],
      "metadata": {
        "id": "xbtwNZXUlgU0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_LPC = []\n",
        "x_valid_LPC = []\n",
        "x_test_LPC = []"
      ],
      "metadata": {
        "id": "BxMLsIKVlqCH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = []\n",
        "y_valid = []\n",
        "y_test = []"
      ],
      "metadata": {
        "id": "OilXnGh3lvn-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_MFCC = []\n",
        "x_valid_MFCC = []\n",
        "x_test_MFCC = []"
      ],
      "metadata": {
        "id": "xTXfZo39lxRM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(460):\n",
        "    x_train_LPC.append(data_train_LPC[i][1])\n",
        "for i in range(105):\n",
        "    x_valid_LPC.append(data_valid_LPC[i][1])\n",
        "for i in range(142):\n",
        "    x_test_LPC.append(data_test_LPC[i][1])"
      ],
      "metadata": {
        "id": "9u2pD-Vin9Xd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(460):\n",
        "    x_train_MFCC.append(data_train_MFCC[i][1])\n",
        "for i in range(105):\n",
        "    x_valid_MFCC.append(data_valid_MFCC[i][1])\n",
        "for i in range(142):\n",
        "    x_test_MFCC.append(data_test_MFCC[i][1])"
      ],
      "metadata": {
        "id": "s1Vy7b9ToOC3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(460):\n",
        "    y_train.append(data_train_LPC[i][2])\n",
        "for i in range(105):\n",
        "    y_valid.append(data_valid_LPC[i][2])\n",
        "for i in range(142):\n",
        "    y_test.append(data_test_LPC[i][2])"
      ],
      "metadata": {
        "id": "aXBcWj_soazB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = [0 if label == 'Normal' else 1 for label in y_train]\n",
        "y_test = [0 if label == 'Normal' else 1 for label in y_test]\n",
        "y_valid = [0 if label == 'Normal' else 1 for label in y_valid]"
      ],
      "metadata": {
        "id": "n5tAbSKll3q0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = np.array(y_train)\n",
        "Y_valid = np.array(y_valid)\n",
        "Y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "WK8JErqJoooK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "149BUCtco0pr",
        "outputId": "b4de2fbc-3111-4b28-f7f0-99470bf021b3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For having same frame numbers, here we add zero instead of features for samples that they have less frames than the 'Average + STD' of all samples' frame numbers."
      ],
      "metadata": {
        "id": "GM_omW2G3ujm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "Z = np.array(z)\n",
        "for i in range (21):\n",
        "  Z[i]=np.float64(Z[i])"
      ],
      "metadata": {
        "id": "SavQq8-gpUft"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "X = np.array(x)\n",
        "for i in range (13):\n",
        "  X[i]=np.float64(X[i])"
      ],
      "metadata": {
        "id": "TwSlI6eyqC0j"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(460):\n",
        "  for j in range(2040-len(x_train_LPC[i])):\n",
        "     x_train_LPC[i] = np.append(x_train_LPC[i], [Z], axis=0)\n",
        "for i in range(105):\n",
        "  for j in range(2040-len(x_valid_LPC[i])):\n",
        "     x_valid_LPC[i] = np.append(x_valid_LPC[i], [Z], axis=0)\n",
        "for i in range(142):\n",
        "  for j in range(2040-len(x_test_LPC[i])):\n",
        "     x_test_LPC[i] = np.append(x_test_LPC[i], [Z], axis=0)"
      ],
      "metadata": {
        "id": "6Td7gTMKplMS"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(460):\n",
        "  for j in range(2045-len(x_train_MFCC[i])):\n",
        "     x_train_MFCC[i] = np.append(x_train_MFCC[i], [X], axis=0)\n",
        "for i in range(105):\n",
        "  for j in range(2045-len(x_valid_MFCC[i])):\n",
        "     x_valid_MFCC[i] = np.append(x_valid_MFCC[i], [X], axis=0)\n",
        "for i in range(142):\n",
        "  for j in range(2045-len(x_test_MFCC[i])):\n",
        "     x_test_MFCC[i] = np.append(x_test_MFCC[i], [X], axis=0)"
      ],
      "metadata": {
        "id": "2AU-Okd0qVNj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_LPC = np.array(x_train_LPC)\n",
        "X_valid_LPC = np.array(x_valid_LPC)\n",
        "X_test_LPC = np.array(x_test_LPC)"
      ],
      "metadata": {
        "id": "LXvmKoHOqzDP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_MFCC = np.array(x_train_MFCC)\n",
        "X_valid_MFCC = np.array(x_valid_MFCC)\n",
        "X_test_MFCC = np.array(x_test_MFCC)"
      ],
      "metadata": {
        "id": "c9DUe4Pwq_d8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization"
      ],
      "metadata": {
        "id": "ha7Tjz4N4SRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def z_score_normalize(data, mean=None, std=None):\n",
        "    if mean is None:\n",
        "        mean = np.mean(data, axis=(0, 1))\n",
        "    if std is None:\n",
        "        std = np.std(data, axis=(0, 1))\n",
        "    normalized_data = (data - mean) / std\n",
        "    return normalized_data, mean, std\n",
        "\n",
        "# Assuming you have train_data, test_data, and valid_data\n",
        "\n",
        "\n",
        "# Calculate mean and std from train_data and normalize all datasets\n",
        "X_train_LPC, mean1, std1 = z_score_normalize(X_train_LPC)\n",
        "X_test_LPC, _, _ = z_score_normalize(X_test_LPC, mean1, std1)\n",
        "X_valid_LPC, _, _ = z_score_normalize(X_valid_LPC, mean1, std1)\n",
        "\n",
        "X_train_MFCC, mean2, std2 = z_score_normalize(X_train_MFCC)\n",
        "X_test_MFCC, _, _ = z_score_normalize(X_test_MFCC, mean2, std2)\n",
        "X_valid_MFCC, _, _ = z_score_normalize(X_valid_MFCC, mean2, std2)"
      ],
      "metadata": {
        "id": "BWQrwkB3rJn8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Proposed CNN Model for Training our Datasets"
      ],
      "metadata": {
        "id": "tWg_IGFT4XsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_LPC = Sequential()\n",
        "# Convolutional Layers\n",
        "model_LPC.add(Conv2D(16, (3, 3), input_shape=(2040, 20, 1), activation='relu', padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model_LPC.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_LPC.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model_LPC.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_LPC.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model_LPC.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Global Average Pooling\n",
        "model_LPC.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Regularization\n",
        "model_LPC.add(Dropout(0.5))\n",
        "\n",
        "# Fully Connected Layers\n",
        "model_LPC.add(Dense(128, activation='relu'))\n",
        "model_LPC.add(Dropout(0.3))\n",
        "\n",
        "model_LPC.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model_LPC.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_LPC.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "JXOeny-Qr_yw",
        "outputId": "3a4ca436-44a5-47a6-a9e2-6b1c137cd650"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2040\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1020\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1020\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2040</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1020</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1020</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,745\u001b[0m (124.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,745</span> (124.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,745\u001b[0m (124.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,745</span> (124.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_MFCC = Sequential()\n",
        "# Convolutional Layers\n",
        "model_MFCC.add(Conv2D(16, (3, 3), input_shape=(2045, 13, 1), activation='relu', padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model_MFCC.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_MFCC.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model_MFCC.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_MFCC.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model_MFCC.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Global Average Pooling\n",
        "model_MFCC.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Regularization\n",
        "model_MFCC.add(Dropout(0.5))\n",
        "\n",
        "# Fully Connected Layers\n",
        "model_MFCC.add(Dense(128, activation='relu'))\n",
        "model_MFCC.add(Dropout(0.3))\n",
        "\n",
        "model_MFCC.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model_MFCC.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_MFCC.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "mpl6Z9U9sqXT",
        "outputId": "65a32df7-ca4d-49c1-9a0b-41a18957b642"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2045\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1022\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1022\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m4,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m511\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m511\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2045</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1022</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1022</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">511</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">511</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,745\u001b[0m (124.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,745</span> (124.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,745\u001b[0m (124.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,745</span> (124.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the trained model for MFCC\n",
        "filepath_MFCC = '/content/sample_data/model_test_MFCC.keras'\n",
        "checkpoint = ModelCheckpoint(filepath=filepath_MFCC,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=0,\n",
        "                             save_best_only=True,\n",
        "                             mode='max')\n",
        "callbacks = [checkpoint]"
      ],
      "metadata": {
        "id": "P2sLIKVUtHW-"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_MFCC.fit(X_train_MFCC, Y_train, validation_data=(X_valid_MFCC, Y_valid),  batch_size=64, epochs=200, callbacks = callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSjusavxtV1k",
        "outputId": "7b17e315-278d-4a50-cdc7-9879ad5a4407"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 689ms/step - accuracy: 0.5393 - loss: 0.6932 - val_accuracy: 0.7714 - val_loss: 0.6730\n",
            "Epoch 2/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5959 - loss: 0.6805 - val_accuracy: 0.7714 - val_loss: 0.6545\n",
            "Epoch 3/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6212 - loss: 0.6698 - val_accuracy: 0.7905 - val_loss: 0.6275\n",
            "Epoch 4/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6889 - loss: 0.6368 - val_accuracy: 0.7810 - val_loss: 0.5862\n",
            "Epoch 5/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7005 - loss: 0.6174 - val_accuracy: 0.7810 - val_loss: 0.5539\n",
            "Epoch 6/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7033 - loss: 0.5913 - val_accuracy: 0.7810 - val_loss: 0.5341\n",
            "Epoch 7/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6978 - loss: 0.5892 - val_accuracy: 0.7810 - val_loss: 0.5292\n",
            "Epoch 8/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7184 - loss: 0.5968 - val_accuracy: 0.8095 - val_loss: 0.5149\n",
            "Epoch 9/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7356 - loss: 0.5789 - val_accuracy: 0.8000 - val_loss: 0.4893\n",
            "Epoch 10/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7799 - loss: 0.5331 - val_accuracy: 0.8000 - val_loss: 0.4724\n",
            "Epoch 11/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7637 - loss: 0.5468 - val_accuracy: 0.8190 - val_loss: 0.4530\n",
            "Epoch 12/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7687 - loss: 0.5277 - val_accuracy: 0.8095 - val_loss: 0.4651\n",
            "Epoch 13/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7448 - loss: 0.5208 - val_accuracy: 0.8190 - val_loss: 0.4585\n",
            "Epoch 14/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8020 - loss: 0.4591 - val_accuracy: 0.8286 - val_loss: 0.4473\n",
            "Epoch 15/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7822 - loss: 0.4909 - val_accuracy: 0.8286 - val_loss: 0.4304\n",
            "Epoch 16/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7811 - loss: 0.4861 - val_accuracy: 0.8381 - val_loss: 0.4247\n",
            "Epoch 17/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8185 - loss: 0.4663 - val_accuracy: 0.8286 - val_loss: 0.4054\n",
            "Epoch 18/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8072 - loss: 0.4367 - val_accuracy: 0.8190 - val_loss: 0.4034\n",
            "Epoch 19/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7978 - loss: 0.4893 - val_accuracy: 0.8381 - val_loss: 0.4027\n",
            "Epoch 20/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8388 - loss: 0.4040 - val_accuracy: 0.8476 - val_loss: 0.4101\n",
            "Epoch 21/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8221 - loss: 0.4278 - val_accuracy: 0.7810 - val_loss: 0.4350\n",
            "Epoch 22/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8069 - loss: 0.4224 - val_accuracy: 0.8190 - val_loss: 0.4310\n",
            "Epoch 23/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8216 - loss: 0.4454 - val_accuracy: 0.8095 - val_loss: 0.4286\n",
            "Epoch 24/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7899 - loss: 0.4387 - val_accuracy: 0.8381 - val_loss: 0.4124\n",
            "Epoch 25/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8584 - loss: 0.3886 - val_accuracy: 0.7429 - val_loss: 0.4947\n",
            "Epoch 26/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7793 - loss: 0.4218 - val_accuracy: 0.7619 - val_loss: 0.4959\n",
            "Epoch 27/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8101 - loss: 0.4554 - val_accuracy: 0.7714 - val_loss: 0.4514\n",
            "Epoch 28/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7695 - loss: 0.4459 - val_accuracy: 0.8381 - val_loss: 0.4150\n",
            "Epoch 29/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8428 - loss: 0.3979 - val_accuracy: 0.8286 - val_loss: 0.3864\n",
            "Epoch 30/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8369 - loss: 0.3835 - val_accuracy: 0.8571 - val_loss: 0.3909\n",
            "Epoch 31/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8643 - loss: 0.3740 - val_accuracy: 0.8381 - val_loss: 0.3940\n",
            "Epoch 32/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8712 - loss: 0.3510 - val_accuracy: 0.8571 - val_loss: 0.3895\n",
            "Epoch 33/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8537 - loss: 0.3544 - val_accuracy: 0.8667 - val_loss: 0.3834\n",
            "Epoch 34/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8689 - loss: 0.3406 - val_accuracy: 0.8571 - val_loss: 0.3917\n",
            "Epoch 35/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8266 - loss: 0.3734 - val_accuracy: 0.8571 - val_loss: 0.3860\n",
            "Epoch 36/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8286 - loss: 0.3633 - val_accuracy: 0.8571 - val_loss: 0.3894\n",
            "Epoch 37/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8305 - loss: 0.3758 - val_accuracy: 0.8571 - val_loss: 0.3876\n",
            "Epoch 38/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8341 - loss: 0.3824 - val_accuracy: 0.8381 - val_loss: 0.4109\n",
            "Epoch 39/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8294 - loss: 0.3522 - val_accuracy: 0.8571 - val_loss: 0.3850\n",
            "Epoch 40/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8454 - loss: 0.3560 - val_accuracy: 0.8381 - val_loss: 0.4023\n",
            "Epoch 41/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8058 - loss: 0.3984 - val_accuracy: 0.8190 - val_loss: 0.4413\n",
            "Epoch 42/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8567 - loss: 0.3323 - val_accuracy: 0.8381 - val_loss: 0.3872\n",
            "Epoch 43/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8315 - loss: 0.3616 - val_accuracy: 0.8381 - val_loss: 0.4070\n",
            "Epoch 44/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8292 - loss: 0.3806 - val_accuracy: 0.8571 - val_loss: 0.3843\n",
            "Epoch 45/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8846 - loss: 0.3101 - val_accuracy: 0.8571 - val_loss: 0.3876\n",
            "Epoch 46/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8429 - loss: 0.3890 - val_accuracy: 0.8667 - val_loss: 0.3967\n",
            "Epoch 47/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8637 - loss: 0.3142 - val_accuracy: 0.8571 - val_loss: 0.3973\n",
            "Epoch 48/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8567 - loss: 0.3326 - val_accuracy: 0.8571 - val_loss: 0.3840\n",
            "Epoch 49/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8762 - loss: 0.3070 - val_accuracy: 0.8762 - val_loss: 0.3820\n",
            "Epoch 50/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8676 - loss: 0.3148 - val_accuracy: 0.8667 - val_loss: 0.3973\n",
            "Epoch 51/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8847 - loss: 0.2791 - val_accuracy: 0.8381 - val_loss: 0.4131\n",
            "Epoch 52/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8517 - loss: 0.3204 - val_accuracy: 0.8476 - val_loss: 0.4149\n",
            "Epoch 53/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8434 - loss: 0.3292 - val_accuracy: 0.8667 - val_loss: 0.3907\n",
            "Epoch 54/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8908 - loss: 0.3088 - val_accuracy: 0.8476 - val_loss: 0.4023\n",
            "Epoch 55/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8512 - loss: 0.3148 - val_accuracy: 0.8381 - val_loss: 0.4190\n",
            "Epoch 56/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8733 - loss: 0.3035 - val_accuracy: 0.8381 - val_loss: 0.4118\n",
            "Epoch 57/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8798 - loss: 0.2872 - val_accuracy: 0.8286 - val_loss: 0.4524\n",
            "Epoch 58/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8494 - loss: 0.3550 - val_accuracy: 0.8762 - val_loss: 0.3835\n",
            "Epoch 59/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8818 - loss: 0.2865 - val_accuracy: 0.8476 - val_loss: 0.4094\n",
            "Epoch 60/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8535 - loss: 0.3332 - val_accuracy: 0.8286 - val_loss: 0.4398\n",
            "Epoch 61/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8682 - loss: 0.3039 - val_accuracy: 0.8190 - val_loss: 0.4618\n",
            "Epoch 62/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8553 - loss: 0.3111 - val_accuracy: 0.8762 - val_loss: 0.3913\n",
            "Epoch 63/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8820 - loss: 0.2658 - val_accuracy: 0.8952 - val_loss: 0.4131\n",
            "Epoch 64/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8727 - loss: 0.3033 - val_accuracy: 0.8762 - val_loss: 0.4471\n",
            "Epoch 65/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8695 - loss: 0.2878 - val_accuracy: 0.8381 - val_loss: 0.4344\n",
            "Epoch 66/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8973 - loss: 0.2530 - val_accuracy: 0.8667 - val_loss: 0.4150\n",
            "Epoch 67/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8600 - loss: 0.3082 - val_accuracy: 0.8762 - val_loss: 0.4055\n",
            "Epoch 68/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8688 - loss: 0.2898 - val_accuracy: 0.8667 - val_loss: 0.4233\n",
            "Epoch 69/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8836 - loss: 0.2703 - val_accuracy: 0.8476 - val_loss: 0.4416\n",
            "Epoch 70/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8705 - loss: 0.2678 - val_accuracy: 0.8381 - val_loss: 0.4634\n",
            "Epoch 71/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8897 - loss: 0.2703 - val_accuracy: 0.8571 - val_loss: 0.4301\n",
            "Epoch 72/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8874 - loss: 0.2676 - val_accuracy: 0.8667 - val_loss: 0.4421\n",
            "Epoch 73/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8750 - loss: 0.2732 - val_accuracy: 0.8762 - val_loss: 0.3936\n",
            "Epoch 74/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9160 - loss: 0.2281 - val_accuracy: 0.8571 - val_loss: 0.4170\n",
            "Epoch 75/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8545 - loss: 0.2901 - val_accuracy: 0.8762 - val_loss: 0.3927\n",
            "Epoch 76/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9041 - loss: 0.2411 - val_accuracy: 0.8667 - val_loss: 0.4215\n",
            "Epoch 77/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9046 - loss: 0.2359 - val_accuracy: 0.8476 - val_loss: 0.4291\n",
            "Epoch 78/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8965 - loss: 0.2419 - val_accuracy: 0.8667 - val_loss: 0.4247\n",
            "Epoch 79/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9132 - loss: 0.2228 - val_accuracy: 0.8476 - val_loss: 0.4488\n",
            "Epoch 80/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9001 - loss: 0.2352 - val_accuracy: 0.8571 - val_loss: 0.4542\n",
            "Epoch 81/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9045 - loss: 0.2206 - val_accuracy: 0.8476 - val_loss: 0.4516\n",
            "Epoch 82/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9090 - loss: 0.2263 - val_accuracy: 0.8571 - val_loss: 0.4807\n",
            "Epoch 83/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9043 - loss: 0.2210 - val_accuracy: 0.8571 - val_loss: 0.4637\n",
            "Epoch 84/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9102 - loss: 0.2137 - val_accuracy: 0.8571 - val_loss: 0.4585\n",
            "Epoch 85/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8902 - loss: 0.2569 - val_accuracy: 0.8571 - val_loss: 0.4400\n",
            "Epoch 86/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8978 - loss: 0.2250 - val_accuracy: 0.8476 - val_loss: 0.4500\n",
            "Epoch 87/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9024 - loss: 0.2362 - val_accuracy: 0.8476 - val_loss: 0.4712\n",
            "Epoch 88/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8954 - loss: 0.2246 - val_accuracy: 0.8190 - val_loss: 0.5074\n",
            "Epoch 89/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9040 - loss: 0.2358 - val_accuracy: 0.8381 - val_loss: 0.4698\n",
            "Epoch 90/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9191 - loss: 0.1860 - val_accuracy: 0.8571 - val_loss: 0.4481\n",
            "Epoch 91/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9079 - loss: 0.2097 - val_accuracy: 0.8571 - val_loss: 0.4573\n",
            "Epoch 92/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9230 - loss: 0.1984 - val_accuracy: 0.8381 - val_loss: 0.4884\n",
            "Epoch 93/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8896 - loss: 0.2335 - val_accuracy: 0.8476 - val_loss: 0.4467\n",
            "Epoch 94/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9058 - loss: 0.2117 - val_accuracy: 0.8381 - val_loss: 0.4746\n",
            "Epoch 95/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9387 - loss: 0.1689 - val_accuracy: 0.8476 - val_loss: 0.4470\n",
            "Epoch 96/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9018 - loss: 0.2164 - val_accuracy: 0.8667 - val_loss: 0.4281\n",
            "Epoch 97/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9249 - loss: 0.1840 - val_accuracy: 0.8476 - val_loss: 0.4896\n",
            "Epoch 98/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9167 - loss: 0.2218 - val_accuracy: 0.8476 - val_loss: 0.5405\n",
            "Epoch 99/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9148 - loss: 0.1976 - val_accuracy: 0.8476 - val_loss: 0.4740\n",
            "Epoch 100/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9113 - loss: 0.2210 - val_accuracy: 0.8571 - val_loss: 0.4521\n",
            "Epoch 101/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8951 - loss: 0.2547 - val_accuracy: 0.8571 - val_loss: 0.4375\n",
            "Epoch 102/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.1994 - val_accuracy: 0.8476 - val_loss: 0.4786\n",
            "Epoch 103/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9267 - loss: 0.1818 - val_accuracy: 0.8286 - val_loss: 0.4894\n",
            "Epoch 104/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9410 - loss: 0.1616 - val_accuracy: 0.8476 - val_loss: 0.4565\n",
            "Epoch 105/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9226 - loss: 0.1841 - val_accuracy: 0.8667 - val_loss: 0.4510\n",
            "Epoch 106/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9206 - loss: 0.1903 - val_accuracy: 0.8476 - val_loss: 0.4899\n",
            "Epoch 107/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9374 - loss: 0.1866 - val_accuracy: 0.8476 - val_loss: 0.4821\n",
            "Epoch 108/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9237 - loss: 0.1815 - val_accuracy: 0.8667 - val_loss: 0.4619\n",
            "Epoch 109/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9358 - loss: 0.1760 - val_accuracy: 0.8571 - val_loss: 0.4682\n",
            "Epoch 110/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9384 - loss: 0.1626 - val_accuracy: 0.8667 - val_loss: 0.5055\n",
            "Epoch 111/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9425 - loss: 0.1768 - val_accuracy: 0.8571 - val_loss: 0.5052\n",
            "Epoch 112/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9297 - loss: 0.1700 - val_accuracy: 0.8762 - val_loss: 0.5145\n",
            "Epoch 113/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9268 - loss: 0.1653 - val_accuracy: 0.8476 - val_loss: 0.4876\n",
            "Epoch 114/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9259 - loss: 0.1730 - val_accuracy: 0.8476 - val_loss: 0.5068\n",
            "Epoch 115/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9245 - loss: 0.1960 - val_accuracy: 0.8476 - val_loss: 0.4890\n",
            "Epoch 116/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9374 - loss: 0.1618 - val_accuracy: 0.8667 - val_loss: 0.4849\n",
            "Epoch 117/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9333 - loss: 0.1688 - val_accuracy: 0.8762 - val_loss: 0.4746\n",
            "Epoch 118/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9242 - loss: 0.1723 - val_accuracy: 0.8571 - val_loss: 0.4985\n",
            "Epoch 119/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9397 - loss: 0.1594 - val_accuracy: 0.8476 - val_loss: 0.4808\n",
            "Epoch 120/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9192 - loss: 0.1777 - val_accuracy: 0.8857 - val_loss: 0.4725\n",
            "Epoch 121/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9452 - loss: 0.1428 - val_accuracy: 0.8571 - val_loss: 0.5543\n",
            "Epoch 122/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9392 - loss: 0.1535 - val_accuracy: 0.8667 - val_loss: 0.5383\n",
            "Epoch 123/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9451 - loss: 0.1475 - val_accuracy: 0.8667 - val_loss: 0.5202\n",
            "Epoch 124/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9330 - loss: 0.1522 - val_accuracy: 0.8571 - val_loss: 0.5087\n",
            "Epoch 125/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9462 - loss: 0.1488 - val_accuracy: 0.8762 - val_loss: 0.5429\n",
            "Epoch 126/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9359 - loss: 0.1338 - val_accuracy: 0.8952 - val_loss: 0.4976\n",
            "Epoch 127/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9537 - loss: 0.1319 - val_accuracy: 0.8952 - val_loss: 0.5066\n",
            "Epoch 128/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9294 - loss: 0.1644 - val_accuracy: 0.8476 - val_loss: 0.6178\n",
            "Epoch 129/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9315 - loss: 0.1553 - val_accuracy: 0.8476 - val_loss: 0.6026\n",
            "Epoch 130/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9223 - loss: 0.1632 - val_accuracy: 0.8571 - val_loss: 0.6372\n",
            "Epoch 131/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9538 - loss: 0.1420 - val_accuracy: 0.8381 - val_loss: 0.6182\n",
            "Epoch 132/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9445 - loss: 0.1641 - val_accuracy: 0.8381 - val_loss: 0.7003\n",
            "Epoch 133/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9324 - loss: 0.1575 - val_accuracy: 0.8381 - val_loss: 0.7212\n",
            "Epoch 134/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9243 - loss: 0.1786 - val_accuracy: 0.8190 - val_loss: 0.7600\n",
            "Epoch 135/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9449 - loss: 0.1639 - val_accuracy: 0.8381 - val_loss: 0.6546\n",
            "Epoch 136/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9577 - loss: 0.1275 - val_accuracy: 0.8286 - val_loss: 0.6260\n",
            "Epoch 137/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9514 - loss: 0.1285 - val_accuracy: 0.8571 - val_loss: 0.5918\n",
            "Epoch 138/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9436 - loss: 0.1523 - val_accuracy: 0.8667 - val_loss: 0.5370\n",
            "Epoch 139/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9368 - loss: 0.1475 - val_accuracy: 0.8857 - val_loss: 0.5256\n",
            "Epoch 140/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9347 - loss: 0.1558 - val_accuracy: 0.8762 - val_loss: 0.5428\n",
            "Epoch 141/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9409 - loss: 0.1515 - val_accuracy: 0.8667 - val_loss: 0.4802\n",
            "Epoch 142/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9443 - loss: 0.1425 - val_accuracy: 0.8762 - val_loss: 0.5613\n",
            "Epoch 143/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9557 - loss: 0.1134 - val_accuracy: 0.8667 - val_loss: 0.6079\n",
            "Epoch 144/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9496 - loss: 0.1337 - val_accuracy: 0.8667 - val_loss: 0.6534\n",
            "Epoch 145/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9550 - loss: 0.1337 - val_accuracy: 0.8000 - val_loss: 0.6894\n",
            "Epoch 146/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9557 - loss: 0.1236 - val_accuracy: 0.8952 - val_loss: 0.5399\n",
            "Epoch 147/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9339 - loss: 0.1457 - val_accuracy: 0.8667 - val_loss: 0.5543\n",
            "Epoch 148/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9387 - loss: 0.1290 - val_accuracy: 0.8476 - val_loss: 0.5962\n",
            "Epoch 149/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.1245 - val_accuracy: 0.8667 - val_loss: 0.5880\n",
            "Epoch 150/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9638 - loss: 0.0985 - val_accuracy: 0.8952 - val_loss: 0.6300\n",
            "Epoch 151/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9631 - loss: 0.1143 - val_accuracy: 0.8762 - val_loss: 0.6365\n",
            "Epoch 152/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9507 - loss: 0.1142 - val_accuracy: 0.8667 - val_loss: 0.6077\n",
            "Epoch 153/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9617 - loss: 0.1130 - val_accuracy: 0.8667 - val_loss: 0.5981\n",
            "Epoch 154/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9723 - loss: 0.0878 - val_accuracy: 0.8667 - val_loss: 0.6217\n",
            "Epoch 155/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9457 - loss: 0.1332 - val_accuracy: 0.8476 - val_loss: 0.6334\n",
            "Epoch 156/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9543 - loss: 0.1073 - val_accuracy: 0.8571 - val_loss: 0.6217\n",
            "Epoch 157/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9666 - loss: 0.1123 - val_accuracy: 0.8571 - val_loss: 0.7301\n",
            "Epoch 158/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9578 - loss: 0.1104 - val_accuracy: 0.8667 - val_loss: 0.6041\n",
            "Epoch 159/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9514 - loss: 0.1305 - val_accuracy: 0.8571 - val_loss: 0.6323\n",
            "Epoch 160/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9467 - loss: 0.1061 - val_accuracy: 0.8762 - val_loss: 0.6332\n",
            "Epoch 161/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9566 - loss: 0.1014 - val_accuracy: 0.8667 - val_loss: 0.6803\n",
            "Epoch 162/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9655 - loss: 0.0876 - val_accuracy: 0.8667 - val_loss: 0.6431\n",
            "Epoch 163/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9666 - loss: 0.0841 - val_accuracy: 0.8571 - val_loss: 0.7699\n",
            "Epoch 164/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9591 - loss: 0.1042 - val_accuracy: 0.8381 - val_loss: 0.7792\n",
            "Epoch 165/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9669 - loss: 0.1036 - val_accuracy: 0.8190 - val_loss: 0.8525\n",
            "Epoch 166/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9422 - loss: 0.1322 - val_accuracy: 0.8571 - val_loss: 0.6790\n",
            "Epoch 167/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9615 - loss: 0.1048 - val_accuracy: 0.8381 - val_loss: 0.7188\n",
            "Epoch 168/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9533 - loss: 0.1103 - val_accuracy: 0.8667 - val_loss: 0.7013\n",
            "Epoch 169/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9695 - loss: 0.0832 - val_accuracy: 0.8667 - val_loss: 0.6815\n",
            "Epoch 170/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9755 - loss: 0.0843 - val_accuracy: 0.8667 - val_loss: 0.6827\n",
            "Epoch 171/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.0842 - val_accuracy: 0.8857 - val_loss: 0.6546\n",
            "Epoch 172/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9693 - loss: 0.1193 - val_accuracy: 0.8857 - val_loss: 0.5986\n",
            "Epoch 173/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9716 - loss: 0.0801 - val_accuracy: 0.8571 - val_loss: 0.6414\n",
            "Epoch 174/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9659 - loss: 0.1021 - val_accuracy: 0.8095 - val_loss: 0.7856\n",
            "Epoch 175/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9744 - loss: 0.1005 - val_accuracy: 0.8762 - val_loss: 0.7201\n",
            "Epoch 176/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9408 - loss: 0.1357 - val_accuracy: 0.8667 - val_loss: 0.6318\n",
            "Epoch 177/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9332 - loss: 0.1477 - val_accuracy: 0.8381 - val_loss: 0.6826\n",
            "Epoch 178/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9436 - loss: 0.1371 - val_accuracy: 0.8762 - val_loss: 0.5739\n",
            "Epoch 179/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9515 - loss: 0.1060 - val_accuracy: 0.8762 - val_loss: 0.6477\n",
            "Epoch 180/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9617 - loss: 0.1128 - val_accuracy: 0.8667 - val_loss: 0.6027\n",
            "Epoch 181/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9623 - loss: 0.0853 - val_accuracy: 0.8476 - val_loss: 0.7040\n",
            "Epoch 182/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9719 - loss: 0.1077 - val_accuracy: 0.8762 - val_loss: 0.7375\n",
            "Epoch 183/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9654 - loss: 0.0923 - val_accuracy: 0.8667 - val_loss: 0.6961\n",
            "Epoch 184/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.0994 - val_accuracy: 0.8667 - val_loss: 0.5814\n",
            "Epoch 185/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9461 - loss: 0.1188 - val_accuracy: 0.8667 - val_loss: 0.5298\n",
            "Epoch 186/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9791 - loss: 0.1076 - val_accuracy: 0.8571 - val_loss: 0.5506\n",
            "Epoch 187/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9388 - loss: 0.1316 - val_accuracy: 0.8667 - val_loss: 0.6197\n",
            "Epoch 188/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9406 - loss: 0.1426 - val_accuracy: 0.8667 - val_loss: 0.5627\n",
            "Epoch 189/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9564 - loss: 0.1157 - val_accuracy: 0.8286 - val_loss: 0.6910\n",
            "Epoch 190/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9573 - loss: 0.1138 - val_accuracy: 0.8762 - val_loss: 0.5828\n",
            "Epoch 191/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9763 - loss: 0.0743 - val_accuracy: 0.8667 - val_loss: 0.6594\n",
            "Epoch 192/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9771 - loss: 0.0777 - val_accuracy: 0.8667 - val_loss: 0.6292\n",
            "Epoch 193/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9741 - loss: 0.0753 - val_accuracy: 0.8762 - val_loss: 0.7234\n",
            "Epoch 194/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9578 - loss: 0.0847 - val_accuracy: 0.8667 - val_loss: 0.7159\n",
            "Epoch 195/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9713 - loss: 0.0645 - val_accuracy: 0.8476 - val_loss: 0.7547\n",
            "Epoch 196/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9592 - loss: 0.1132 - val_accuracy: 0.8667 - val_loss: 0.6724\n",
            "Epoch 197/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9672 - loss: 0.0798 - val_accuracy: 0.8571 - val_loss: 0.7627\n",
            "Epoch 198/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9470 - loss: 0.1009 - val_accuracy: 0.8571 - val_loss: 0.7169\n",
            "Epoch 199/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9586 - loss: 0.0898 - val_accuracy: 0.8667 - val_loss: 0.7109\n",
            "Epoch 200/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9261 - loss: 0.1468 - val_accuracy: 0.8667 - val_loss: 0.6641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(filepath_MFCC)"
      ],
      "metadata": {
        "id": "BN-crOUsuBCW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracies of the model for test and validation data by MFCC Features"
      ],
      "metadata": {
        "id": "SNYeBSEy4pWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_valid_MFCC,Y_valid, verbose=0)\n",
        "print(\"validation Accuracy by MFCC: \",test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QDJcIfLu3xH",
        "outputId": "962081f6-e86f-4db7-bb95-ef696f0f97f4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation Accuracy by MFCC:  0.8952381014823914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test_MFCC,Y_test, verbose=0)\n",
        "print(\"Test Accuracy by MFCC: \",test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YMVEJDGt1sP",
        "outputId": "d7d5f2ad-41c5-4915-be2a-7e22b061d940"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy by MFCC:  0.8450704216957092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the trained model for lpc\n",
        "filepath_LPC = '/content/sample_data/model_test_LPC.keras'\n",
        "checkpoint = ModelCheckpoint(filepath=filepath_LPC,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=0,\n",
        "                             save_best_only=True,\n",
        "                             mode='max')\n",
        "callbacks = [checkpoint]"
      ],
      "metadata": {
        "id": "MrShNn0GvGRC"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_LPC.fit(X_train_LPC, Y_train, validation_data=(X_valid_LPC, Y_valid),  batch_size=64, epochs=200, callbacks = callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DguF8tIovS91",
        "outputId": "cb6b5e18-ac23-4a7d-c694-b0e66e7178e1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 528ms/step - accuracy: 0.4773 - loss: 0.6905 - val_accuracy: 0.5524 - val_loss: 0.6849\n",
            "Epoch 2/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5146 - loss: 0.6823 - val_accuracy: 0.6190 - val_loss: 0.6801\n",
            "Epoch 3/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5642 - loss: 0.6791 - val_accuracy: 0.6667 - val_loss: 0.6713\n",
            "Epoch 4/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5817 - loss: 0.6746 - val_accuracy: 0.6476 - val_loss: 0.6639\n",
            "Epoch 5/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5905 - loss: 0.6798 - val_accuracy: 0.6000 - val_loss: 0.6638\n",
            "Epoch 6/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6465 - loss: 0.6703 - val_accuracy: 0.6762 - val_loss: 0.6521\n",
            "Epoch 7/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6314 - loss: 0.6603 - val_accuracy: 0.6000 - val_loss: 0.6528\n",
            "Epoch 8/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5855 - loss: 0.6583 - val_accuracy: 0.6000 - val_loss: 0.6458\n",
            "Epoch 9/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6028 - loss: 0.6548 - val_accuracy: 0.6571 - val_loss: 0.6298\n",
            "Epoch 10/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5969 - loss: 0.6558 - val_accuracy: 0.6571 - val_loss: 0.6274\n",
            "Epoch 11/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6310 - loss: 0.6546 - val_accuracy: 0.6667 - val_loss: 0.6161\n",
            "Epoch 12/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6524 - loss: 0.6356 - val_accuracy: 0.6476 - val_loss: 0.6162\n",
            "Epoch 13/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6476 - loss: 0.6159 - val_accuracy: 0.7333 - val_loss: 0.5823\n",
            "Epoch 14/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6836 - loss: 0.6196 - val_accuracy: 0.6667 - val_loss: 0.5942\n",
            "Epoch 15/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6424 - loss: 0.6178 - val_accuracy: 0.7429 - val_loss: 0.5799\n",
            "Epoch 16/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6547 - loss: 0.6314 - val_accuracy: 0.6857 - val_loss: 0.5897\n",
            "Epoch 17/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6488 - loss: 0.6493 - val_accuracy: 0.6762 - val_loss: 0.5821\n",
            "Epoch 18/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6608 - loss: 0.5943 - val_accuracy: 0.7714 - val_loss: 0.5478\n",
            "Epoch 19/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6837 - loss: 0.5957 - val_accuracy: 0.6857 - val_loss: 0.5621\n",
            "Epoch 20/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6856 - loss: 0.5867 - val_accuracy: 0.7905 - val_loss: 0.5401\n",
            "Epoch 21/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7210 - loss: 0.6220 - val_accuracy: 0.6476 - val_loss: 0.6393\n",
            "Epoch 22/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6334 - loss: 0.6029 - val_accuracy: 0.7810 - val_loss: 0.5458\n",
            "Epoch 23/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7204 - loss: 0.5750 - val_accuracy: 0.6762 - val_loss: 0.5628\n",
            "Epoch 24/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6960 - loss: 0.5747 - val_accuracy: 0.8000 - val_loss: 0.5105\n",
            "Epoch 25/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7168 - loss: 0.5471 - val_accuracy: 0.7905 - val_loss: 0.5188\n",
            "Epoch 26/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7564 - loss: 0.5251 - val_accuracy: 0.7810 - val_loss: 0.5218\n",
            "Epoch 27/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7133 - loss: 0.5695 - val_accuracy: 0.7714 - val_loss: 0.5133\n",
            "Epoch 28/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7624 - loss: 0.5777 - val_accuracy: 0.6762 - val_loss: 0.5562\n",
            "Epoch 29/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6856 - loss: 0.5567 - val_accuracy: 0.8190 - val_loss: 0.4957\n",
            "Epoch 30/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7292 - loss: 0.5698 - val_accuracy: 0.7905 - val_loss: 0.4663\n",
            "Epoch 31/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7034 - loss: 0.5336 - val_accuracy: 0.8000 - val_loss: 0.4479\n",
            "Epoch 32/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7792 - loss: 0.4981 - val_accuracy: 0.8000 - val_loss: 0.4504\n",
            "Epoch 33/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7354 - loss: 0.5197 - val_accuracy: 0.8095 - val_loss: 0.4340\n",
            "Epoch 34/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7980 - loss: 0.4883 - val_accuracy: 0.8190 - val_loss: 0.4554\n",
            "Epoch 35/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7195 - loss: 0.5123 - val_accuracy: 0.8190 - val_loss: 0.4231\n",
            "Epoch 36/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7571 - loss: 0.4919 - val_accuracy: 0.7810 - val_loss: 0.4080\n",
            "Epoch 37/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8267 - loss: 0.4720 - val_accuracy: 0.8286 - val_loss: 0.4380\n",
            "Epoch 38/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7635 - loss: 0.4670 - val_accuracy: 0.8000 - val_loss: 0.4030\n",
            "Epoch 39/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7823 - loss: 0.4547 - val_accuracy: 0.8000 - val_loss: 0.3962\n",
            "Epoch 40/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7803 - loss: 0.4541 - val_accuracy: 0.8190 - val_loss: 0.3905\n",
            "Epoch 41/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7640 - loss: 0.4473 - val_accuracy: 0.8476 - val_loss: 0.3866\n",
            "Epoch 42/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8095 - loss: 0.4499 - val_accuracy: 0.7714 - val_loss: 0.4586\n",
            "Epoch 43/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7757 - loss: 0.4460 - val_accuracy: 0.8381 - val_loss: 0.3798\n",
            "Epoch 44/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7804 - loss: 0.4637 - val_accuracy: 0.8190 - val_loss: 0.3988\n",
            "Epoch 45/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7797 - loss: 0.4467 - val_accuracy: 0.8095 - val_loss: 0.3768\n",
            "Epoch 46/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7951 - loss: 0.4263 - val_accuracy: 0.8095 - val_loss: 0.3627\n",
            "Epoch 47/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8208 - loss: 0.4279 - val_accuracy: 0.8286 - val_loss: 0.3887\n",
            "Epoch 48/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7771 - loss: 0.4217 - val_accuracy: 0.8381 - val_loss: 0.3586\n",
            "Epoch 49/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7562 - loss: 0.4784 - val_accuracy: 0.8190 - val_loss: 0.3750\n",
            "Epoch 50/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8156 - loss: 0.4282 - val_accuracy: 0.8286 - val_loss: 0.3469\n",
            "Epoch 51/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7895 - loss: 0.4150 - val_accuracy: 0.8381 - val_loss: 0.3441\n",
            "Epoch 52/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8119 - loss: 0.4182 - val_accuracy: 0.8286 - val_loss: 0.3441\n",
            "Epoch 53/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8156 - loss: 0.4157 - val_accuracy: 0.8667 - val_loss: 0.3389\n",
            "Epoch 54/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8007 - loss: 0.4440 - val_accuracy: 0.8381 - val_loss: 0.4118\n",
            "Epoch 55/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7702 - loss: 0.4458 - val_accuracy: 0.8476 - val_loss: 0.3534\n",
            "Epoch 56/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8057 - loss: 0.4207 - val_accuracy: 0.8381 - val_loss: 0.3648\n",
            "Epoch 57/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8306 - loss: 0.4018 - val_accuracy: 0.8476 - val_loss: 0.3360\n",
            "Epoch 58/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8203 - loss: 0.3806 - val_accuracy: 0.8190 - val_loss: 0.3411\n",
            "Epoch 59/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8432 - loss: 0.3552 - val_accuracy: 0.8286 - val_loss: 0.3307\n",
            "Epoch 60/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8290 - loss: 0.3602 - val_accuracy: 0.8381 - val_loss: 0.4141\n",
            "Epoch 61/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8292 - loss: 0.4057 - val_accuracy: 0.8476 - val_loss: 0.3622\n",
            "Epoch 62/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8103 - loss: 0.4087 - val_accuracy: 0.8000 - val_loss: 0.3853\n",
            "Epoch 63/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8188 - loss: 0.3979 - val_accuracy: 0.8286 - val_loss: 0.3395\n",
            "Epoch 64/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8482 - loss: 0.3549 - val_accuracy: 0.8381 - val_loss: 0.3291\n",
            "Epoch 65/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8313 - loss: 0.3676 - val_accuracy: 0.8286 - val_loss: 0.3168\n",
            "Epoch 66/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8527 - loss: 0.3538 - val_accuracy: 0.8286 - val_loss: 0.3344\n",
            "Epoch 67/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8117 - loss: 0.3835 - val_accuracy: 0.8381 - val_loss: 0.3498\n",
            "Epoch 68/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8133 - loss: 0.3690 - val_accuracy: 0.8476 - val_loss: 0.3217\n",
            "Epoch 69/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8423 - loss: 0.3509 - val_accuracy: 0.8571 - val_loss: 0.3478\n",
            "Epoch 70/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8538 - loss: 0.3631 - val_accuracy: 0.8476 - val_loss: 0.3184\n",
            "Epoch 71/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8502 - loss: 0.3664 - val_accuracy: 0.8476 - val_loss: 0.3228\n",
            "Epoch 72/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8375 - loss: 0.3483 - val_accuracy: 0.8476 - val_loss: 0.3284\n",
            "Epoch 73/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8433 - loss: 0.3454 - val_accuracy: 0.8476 - val_loss: 0.3307\n",
            "Epoch 74/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8331 - loss: 0.3531 - val_accuracy: 0.8286 - val_loss: 0.3634\n",
            "Epoch 75/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8422 - loss: 0.3476 - val_accuracy: 0.8286 - val_loss: 0.3432\n",
            "Epoch 76/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8754 - loss: 0.3175 - val_accuracy: 0.8476 - val_loss: 0.3526\n",
            "Epoch 77/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8417 - loss: 0.3305 - val_accuracy: 0.8571 - val_loss: 0.3203\n",
            "Epoch 78/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8621 - loss: 0.3491 - val_accuracy: 0.8762 - val_loss: 0.3212\n",
            "Epoch 79/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8606 - loss: 0.3448 - val_accuracy: 0.8476 - val_loss: 0.3499\n",
            "Epoch 80/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8579 - loss: 0.3217 - val_accuracy: 0.8571 - val_loss: 0.3213\n",
            "Epoch 81/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8498 - loss: 0.3190 - val_accuracy: 0.8667 - val_loss: 0.3458\n",
            "Epoch 82/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8323 - loss: 0.3394 - val_accuracy: 0.8476 - val_loss: 0.3146\n",
            "Epoch 83/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8485 - loss: 0.3506 - val_accuracy: 0.8857 - val_loss: 0.3235\n",
            "Epoch 84/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8681 - loss: 0.3161 - val_accuracy: 0.8667 - val_loss: 0.2969\n",
            "Epoch 85/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8716 - loss: 0.3072 - val_accuracy: 0.8667 - val_loss: 0.3264\n",
            "Epoch 86/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8761 - loss: 0.3041 - val_accuracy: 0.8571 - val_loss: 0.3212\n",
            "Epoch 87/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8722 - loss: 0.3137 - val_accuracy: 0.8571 - val_loss: 0.3338\n",
            "Epoch 88/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8874 - loss: 0.3178 - val_accuracy: 0.8667 - val_loss: 0.3310\n",
            "Epoch 89/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8705 - loss: 0.3055 - val_accuracy: 0.8286 - val_loss: 0.4071\n",
            "Epoch 90/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8643 - loss: 0.3088 - val_accuracy: 0.8762 - val_loss: 0.2966\n",
            "Epoch 91/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8818 - loss: 0.3260 - val_accuracy: 0.8762 - val_loss: 0.3042\n",
            "Epoch 92/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8500 - loss: 0.3473 - val_accuracy: 0.8571 - val_loss: 0.3266\n",
            "Epoch 93/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8991 - loss: 0.3012 - val_accuracy: 0.8571 - val_loss: 0.3348\n",
            "Epoch 94/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8864 - loss: 0.2865 - val_accuracy: 0.8762 - val_loss: 0.3167\n",
            "Epoch 95/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8744 - loss: 0.2880 - val_accuracy: 0.8667 - val_loss: 0.3472\n",
            "Epoch 96/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8726 - loss: 0.3112 - val_accuracy: 0.8762 - val_loss: 0.3026\n",
            "Epoch 97/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8733 - loss: 0.3188 - val_accuracy: 0.8762 - val_loss: 0.3127\n",
            "Epoch 98/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8630 - loss: 0.3045 - val_accuracy: 0.8952 - val_loss: 0.3058\n",
            "Epoch 99/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8863 - loss: 0.2937 - val_accuracy: 0.8667 - val_loss: 0.3116\n",
            "Epoch 100/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8577 - loss: 0.3235 - val_accuracy: 0.8667 - val_loss: 0.3138\n",
            "Epoch 101/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8604 - loss: 0.2873 - val_accuracy: 0.8571 - val_loss: 0.3683\n",
            "Epoch 102/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8743 - loss: 0.3069 - val_accuracy: 0.8762 - val_loss: 0.2933\n",
            "Epoch 103/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8708 - loss: 0.2920 - val_accuracy: 0.8667 - val_loss: 0.3217\n",
            "Epoch 104/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8903 - loss: 0.2947 - val_accuracy: 0.8857 - val_loss: 0.3035\n",
            "Epoch 105/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8923 - loss: 0.2870 - val_accuracy: 0.8762 - val_loss: 0.3028\n",
            "Epoch 106/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9107 - loss: 0.2569 - val_accuracy: 0.8952 - val_loss: 0.3161\n",
            "Epoch 107/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9161 - loss: 0.2506 - val_accuracy: 0.9048 - val_loss: 0.2946\n",
            "Epoch 108/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9016 - loss: 0.2530 - val_accuracy: 0.8952 - val_loss: 0.3225\n",
            "Epoch 109/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8879 - loss: 0.2732 - val_accuracy: 0.8381 - val_loss: 0.3729\n",
            "Epoch 110/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8875 - loss: 0.2649 - val_accuracy: 0.8762 - val_loss: 0.3197\n",
            "Epoch 111/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8900 - loss: 0.2727 - val_accuracy: 0.8857 - val_loss: 0.3173\n",
            "Epoch 112/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8916 - loss: 0.2348 - val_accuracy: 0.8762 - val_loss: 0.3198\n",
            "Epoch 113/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9124 - loss: 0.2343 - val_accuracy: 0.8762 - val_loss: 0.3700\n",
            "Epoch 114/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9022 - loss: 0.2516 - val_accuracy: 0.8762 - val_loss: 0.3554\n",
            "Epoch 115/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9240 - loss: 0.2126 - val_accuracy: 0.9048 - val_loss: 0.3373\n",
            "Epoch 116/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9057 - loss: 0.2240 - val_accuracy: 0.8667 - val_loss: 0.3222\n",
            "Epoch 117/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9327 - loss: 0.2275 - val_accuracy: 0.8667 - val_loss: 0.3514\n",
            "Epoch 118/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9058 - loss: 0.2422 - val_accuracy: 0.8667 - val_loss: 0.3549\n",
            "Epoch 119/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8860 - loss: 0.2460 - val_accuracy: 0.8857 - val_loss: 0.3130\n",
            "Epoch 120/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9067 - loss: 0.2378 - val_accuracy: 0.8571 - val_loss: 0.3622\n",
            "Epoch 121/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9203 - loss: 0.2405 - val_accuracy: 0.8667 - val_loss: 0.3280\n",
            "Epoch 122/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8803 - loss: 0.2657 - val_accuracy: 0.8667 - val_loss: 0.3753\n",
            "Epoch 123/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9262 - loss: 0.2256 - val_accuracy: 0.8667 - val_loss: 0.3701\n",
            "Epoch 124/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8894 - loss: 0.2477 - val_accuracy: 0.8476 - val_loss: 0.4205\n",
            "Epoch 125/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8565 - loss: 0.3114 - val_accuracy: 0.8762 - val_loss: 0.3179\n",
            "Epoch 126/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9283 - loss: 0.2146 - val_accuracy: 0.8857 - val_loss: 0.3083\n",
            "Epoch 127/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9057 - loss: 0.2558 - val_accuracy: 0.8667 - val_loss: 0.3107\n",
            "Epoch 128/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8862 - loss: 0.2688 - val_accuracy: 0.8762 - val_loss: 0.3683\n",
            "Epoch 129/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9174 - loss: 0.2068 - val_accuracy: 0.8381 - val_loss: 0.3626\n",
            "Epoch 130/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9331 - loss: 0.2156 - val_accuracy: 0.8952 - val_loss: 0.3133\n",
            "Epoch 131/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9215 - loss: 0.2243 - val_accuracy: 0.8952 - val_loss: 0.3106\n",
            "Epoch 132/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9203 - loss: 0.2221 - val_accuracy: 0.8571 - val_loss: 0.3668\n",
            "Epoch 133/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9157 - loss: 0.2154 - val_accuracy: 0.8762 - val_loss: 0.3154\n",
            "Epoch 134/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9174 - loss: 0.2124 - val_accuracy: 0.8667 - val_loss: 0.3216\n",
            "Epoch 135/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9280 - loss: 0.1933 - val_accuracy: 0.8762 - val_loss: 0.3415\n",
            "Epoch 136/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9380 - loss: 0.1837 - val_accuracy: 0.8286 - val_loss: 0.4915\n",
            "Epoch 137/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9042 - loss: 0.2469 - val_accuracy: 0.8476 - val_loss: 0.3350\n",
            "Epoch 138/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9171 - loss: 0.2114 - val_accuracy: 0.8571 - val_loss: 0.3297\n",
            "Epoch 139/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9293 - loss: 0.2079 - val_accuracy: 0.8476 - val_loss: 0.4646\n",
            "Epoch 140/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9013 - loss: 0.2181 - val_accuracy: 0.8571 - val_loss: 0.3654\n",
            "Epoch 141/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9459 - loss: 0.1754 - val_accuracy: 0.8571 - val_loss: 0.3727\n",
            "Epoch 142/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8750 - loss: 0.2798 - val_accuracy: 0.8762 - val_loss: 0.3316\n",
            "Epoch 143/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9199 - loss: 0.2115 - val_accuracy: 0.8857 - val_loss: 0.3218\n",
            "Epoch 144/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9214 - loss: 0.2163 - val_accuracy: 0.8857 - val_loss: 0.3364\n",
            "Epoch 145/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9237 - loss: 0.1789 - val_accuracy: 0.8476 - val_loss: 0.4350\n",
            "Epoch 146/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9236 - loss: 0.2067 - val_accuracy: 0.8667 - val_loss: 0.3407\n",
            "Epoch 147/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9388 - loss: 0.1742 - val_accuracy: 0.8571 - val_loss: 0.4106\n",
            "Epoch 148/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9187 - loss: 0.1946 - val_accuracy: 0.8381 - val_loss: 0.4094\n",
            "Epoch 149/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9354 - loss: 0.1726 - val_accuracy: 0.8571 - val_loss: 0.4194\n",
            "Epoch 150/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9332 - loss: 0.1640 - val_accuracy: 0.8667 - val_loss: 0.3774\n",
            "Epoch 151/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9273 - loss: 0.1780 - val_accuracy: 0.8667 - val_loss: 0.3679\n",
            "Epoch 152/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9270 - loss: 0.1917 - val_accuracy: 0.8476 - val_loss: 0.3806\n",
            "Epoch 153/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9183 - loss: 0.2072 - val_accuracy: 0.8857 - val_loss: 0.3385\n",
            "Epoch 154/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9475 - loss: 0.1501 - val_accuracy: 0.8857 - val_loss: 0.3498\n",
            "Epoch 155/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9451 - loss: 0.1536 - val_accuracy: 0.8286 - val_loss: 0.5002\n",
            "Epoch 156/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9171 - loss: 0.1964 - val_accuracy: 0.8667 - val_loss: 0.3735\n",
            "Epoch 157/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9176 - loss: 0.2038 - val_accuracy: 0.8286 - val_loss: 0.4544\n",
            "Epoch 158/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9107 - loss: 0.2113 - val_accuracy: 0.8476 - val_loss: 0.4601\n",
            "Epoch 159/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9620 - loss: 0.1443 - val_accuracy: 0.8667 - val_loss: 0.3641\n",
            "Epoch 160/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9397 - loss: 0.1731 - val_accuracy: 0.8571 - val_loss: 0.3666\n",
            "Epoch 161/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9365 - loss: 0.1582 - val_accuracy: 0.8286 - val_loss: 0.5065\n",
            "Epoch 162/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9291 - loss: 0.2088 - val_accuracy: 0.8762 - val_loss: 0.3184\n",
            "Epoch 163/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9470 - loss: 0.1554 - val_accuracy: 0.8952 - val_loss: 0.3340\n",
            "Epoch 164/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9374 - loss: 0.1690 - val_accuracy: 0.8857 - val_loss: 0.3530\n",
            "Epoch 165/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9440 - loss: 0.1315 - val_accuracy: 0.8857 - val_loss: 0.3813\n",
            "Epoch 166/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9253 - loss: 0.1807 - val_accuracy: 0.8667 - val_loss: 0.4097\n",
            "Epoch 167/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9448 - loss: 0.1381 - val_accuracy: 0.8667 - val_loss: 0.3861\n",
            "Epoch 168/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9627 - loss: 0.1122 - val_accuracy: 0.8190 - val_loss: 0.5316\n",
            "Epoch 169/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9324 - loss: 0.1724 - val_accuracy: 0.8952 - val_loss: 0.3695\n",
            "Epoch 170/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9599 - loss: 0.1261 - val_accuracy: 0.8952 - val_loss: 0.3650\n",
            "Epoch 171/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9551 - loss: 0.1455 - val_accuracy: 0.8476 - val_loss: 0.4290\n",
            "Epoch 172/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9547 - loss: 0.1455 - val_accuracy: 0.8381 - val_loss: 0.4322\n",
            "Epoch 173/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9669 - loss: 0.1101 - val_accuracy: 0.8381 - val_loss: 0.4211\n",
            "Epoch 174/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9672 - loss: 0.1076 - val_accuracy: 0.8476 - val_loss: 0.4126\n",
            "Epoch 175/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9551 - loss: 0.1179 - val_accuracy: 0.8571 - val_loss: 0.4218\n",
            "Epoch 176/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9531 - loss: 0.1419 - val_accuracy: 0.8476 - val_loss: 0.3980\n",
            "Epoch 177/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9572 - loss: 0.1203 - val_accuracy: 0.8762 - val_loss: 0.3989\n",
            "Epoch 178/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9616 - loss: 0.1284 - val_accuracy: 0.8095 - val_loss: 0.4974\n",
            "Epoch 179/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9207 - loss: 0.1825 - val_accuracy: 0.8571 - val_loss: 0.4209\n",
            "Epoch 180/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9420 - loss: 0.1607 - val_accuracy: 0.8476 - val_loss: 0.3827\n",
            "Epoch 181/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9533 - loss: 0.1475 - val_accuracy: 0.8476 - val_loss: 0.5016\n",
            "Epoch 182/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9477 - loss: 0.1304 - val_accuracy: 0.8476 - val_loss: 0.4619\n",
            "Epoch 183/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9618 - loss: 0.1117 - val_accuracy: 0.8571 - val_loss: 0.4951\n",
            "Epoch 184/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9570 - loss: 0.1264 - val_accuracy: 0.8476 - val_loss: 0.5559\n",
            "Epoch 185/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9315 - loss: 0.1863 - val_accuracy: 0.8381 - val_loss: 0.4805\n",
            "Epoch 186/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9514 - loss: 0.1456 - val_accuracy: 0.8476 - val_loss: 0.4415\n",
            "Epoch 187/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9442 - loss: 0.1478 - val_accuracy: 0.8571 - val_loss: 0.4130\n",
            "Epoch 188/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9665 - loss: 0.1134 - val_accuracy: 0.8857 - val_loss: 0.4061\n",
            "Epoch 189/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9562 - loss: 0.1409 - val_accuracy: 0.8476 - val_loss: 0.3911\n",
            "Epoch 190/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9628 - loss: 0.1192 - val_accuracy: 0.8381 - val_loss: 0.4217\n",
            "Epoch 191/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9573 - loss: 0.1253 - val_accuracy: 0.8762 - val_loss: 0.3939\n",
            "Epoch 192/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9470 - loss: 0.1441 - val_accuracy: 0.8667 - val_loss: 0.4364\n",
            "Epoch 193/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9706 - loss: 0.1055 - val_accuracy: 0.8667 - val_loss: 0.4180\n",
            "Epoch 194/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9604 - loss: 0.1401 - val_accuracy: 0.8762 - val_loss: 0.3929\n",
            "Epoch 195/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9552 - loss: 0.1313 - val_accuracy: 0.8381 - val_loss: 0.5350\n",
            "Epoch 196/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9455 - loss: 0.1405 - val_accuracy: 0.8667 - val_loss: 0.4226\n",
            "Epoch 197/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9764 - loss: 0.0941 - val_accuracy: 0.8571 - val_loss: 0.4728\n",
            "Epoch 198/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9651 - loss: 0.0877 - val_accuracy: 0.8476 - val_loss: 0.5366\n",
            "Epoch 199/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9698 - loss: 0.1024 - val_accuracy: 0.8762 - val_loss: 0.4393\n",
            "Epoch 200/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9599 - loss: 0.1280 - val_accuracy: 0.8571 - val_loss: 0.4246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(filepath_LPC)"
      ],
      "metadata": {
        "id": "DRMvJuclvp9K"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracies of the model for test and validation data by LPC Features"
      ],
      "metadata": {
        "id": "PJ4rXti_446Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_valid_LPC,Y_valid, verbose=0)\n",
        "print(\"validation Accuracy by LPC: \",test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HSXQrWlvuaw",
        "outputId": "8518af37-fee1-4676-9542-89fe6fafc8fc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation Accuracy by LPC:  0.9047619104385376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test_LPC,Y_test, verbose=0)\n",
        "print(\"test Accuracy by LPC: \",test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LjAH5BDv4LY",
        "outputId": "b57e4bc8-b06f-4db4-c643-2be14cd35ec1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Accuracy by LPC:  0.8661971688270569\n"
          ]
        }
      ]
    }
  ]
}